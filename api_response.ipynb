{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/Frontend/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "genai.configure(api_key='AIzaSyAo2VAV4eGFv5wqByYUw6yP-Sjh8Va9z5c')\n",
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "chat = model.start_chat(history=[])\n",
    "response = chat.send_message(\"我是一个在学习日语的中国大学生，我希望你能够帮我学习新学习到的词汇，我将会给你一些新学到的词汇，请你基于我给出的词汇，写一篇日文短文，使得这些词汇都能够被用到。我将会使用符号分割他们。你的回答按照如下结构：1.短文故事;2.短文中文翻译;3.词汇与解释;4.语法解释（初级以上的语法才解释）\")\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"寝巻き｜型付け｜昼食｜棚｜お礼｜従兄弟｜叫ぶ｜聞かせる｜ドラマ｜可愛がる｜留守｜歴史\")\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_content_after_hashes(markdown_text):\n",
    "    pattern = \"## .* ##\\n\\n(.*?)\\n\\n##\"\n",
    "    matches = re.findall(pattern, markdown_text, re.DOTALL)\n",
    "    return matches\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "## Section 1 ##\n",
    "\n",
    "This is some text.\n",
    "\n",
    "## Section 2 ##\n",
    "\n",
    "This is some more text.\n",
    "\"\"\"\n",
    "\n",
    "print(get_content_after_hashes(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将Markdown字符串保存为.md文件\n",
    "with open('output.md', 'w', encoding='utf-8') as file:\n",
    "    file.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from md2pdf.core import md2pdf\n",
    "\n",
    "md2pdf('./output.pdf',response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_text='<ruby>日本<rt>にっぽん</rt></ruby>'\n",
    "md2pdf('./output2.pdf',try_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markdown\n",
    "import pdfkit\n",
    "\n",
    "config = pdfkit.configuration(wkhtmltopdf=r'C:\\Program Files\\wkhtmltopdf\\bin\\wkhtmltopdf.exe')\n",
    "options = {\n",
    "'no-stop-slow-scripts': None,\n",
    "'image-quality': '100',\n",
    "'enable-local-file-access': None,\n",
    "'margin-top': '0',\n",
    "'page-size': 'A4',\n",
    "'margin-right': '0',\n",
    "'margin-bottom': '0',\n",
    "'margin-left': '0',\n",
    "'encoding': \"UTF-8\"}\n",
    "\n",
    "options2 = {\n",
    "    'no-stop-slow-scripts': None,\n",
    "    'image-quality': '100',\n",
    "    'enable-local-file-access': None,\n",
    "    'margin-top': '0',\n",
    "    'page-size': 'A4',\n",
    "    'margin-right': '0',\n",
    "    'margin-bottom': '0',\n",
    "    'margin-left': '0',\n",
    "    'encoding': \"UTF-8\",\n",
    "    'orientation': 'Landscape'  # 设置页面为横向\n",
    "}\n",
    "html_text = markdown.markdown(response.text)\n",
    "# 使用pdfkit将HTML转换为PDF\n",
    "# pdfkit.from_string(html_text, 'output3.pdf',configuration=config,options=options2)\n",
    "\n",
    "# print(\"PDF文件已生成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text\n",
    "# 将Markdown字符串保存为.md文件\n",
    "with open('output.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# 解析HTML内容\n",
    "a=[]\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "h2_tags = soup.find_all('h2')\n",
    "for h2_tag in h2_tags:\n",
    "    if h2_tag.text.strip() == '短文故事：':\n",
    "        # 找到<h2>标签后的所有兄弟节点，直到下一个<h2>标签\n",
    "        for sibling in h2_tag.find_next_siblings():\n",
    "            if sibling.name == 'h2':\n",
    "                break\n",
    "            if sibling.name == 'p':\n",
    "                a.append(sibling.text)\n",
    "                print(sibling.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykakasi import kakasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kakasi_instance = kakasi()\n",
    "converted_text = kakasi_instance.convert(a[0])\n",
    "for i in a:\n",
    "    converted_text = kakasi_instance.convert(i)\n",
    "    after_text=''\n",
    "    for i in converted_text:\n",
    "        if i['orig'] == i['hira']:\n",
    "            after_text += i['orig']\n",
    "        else:\n",
    "            after_text += '<ruby>'+i['orig']+'<rt>'+i['hira']+'</rt></ruby>'\n",
    "    after_text += ''\n",
    "    print(after_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=['nihao','hello']\n",
    "sum(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
